---
layout:     post
title:      Domain-specific Application of ChatGPT
date:       2022-12-28 21:46:00
summary:    A Large-Language Model is only useful when it is well understood.
categories: chatgpt, machine learning, technology, finance
---

<blockquote>
  <p>Either you run the day, or the day runs you.</p>
  <footer><cite title="Boss Baby">Boss Baby</cite></footer>
</blockquote>

# What is ChatGPT

* It is a *Large Language Model (LLM)* - ChatGPT originates from [*Generative
  Pre-trained Transformer 3
  (GPT-3.5)*](https://beta.openai.com/docs/model-index-for-researchers) which is
  a deep neural network based model with more than **175 billion parameters**.  
* The model is generatively pre-trained with the large scale data sets such as
  [Common Crawl](https://en.wikipedia.org/wiki/Common_Crawl),
  [WebTex2](https://github.com/EleutherAI/The-Pile/issues/6), etc.
* The training process applies the *Reinforcement Learning with Human Feedback
  (RLHF)* technique, which presents human preferences to the model and tune the
  model responses based on them.
* It exposes the user interfaces to interact with the model in a dialogue
  approach. 

# How it works

In general, the creation of ChatGPT is performed in the following steps.

1. Prompts of various categories, e.g., Q&A, rewrite, summarise, etc., are
   sampled and labelled for tuning the pre-trained GPT-3.5 model in a supervised
   approach. 
1. The fine-tuned model is used to generate outputs from another set of sampled
   prompts and the results are ranked by human labor (from best to worst). The
   ranked outputs are used for building *reward model*.
1. The RL algorithm (*Proximal Policy Optimization*) initialized the supervised
   model (or *policy* as in RL context) for the new prompts - it uses the reward
   model that minimizes the prediction and the human labelled preferences -
   based on the outputs the policy is updated by the algorithm.

# Take a closer look...

## Where the charm comes from

The key factors for the impressive performance of ChatGPT on the demonstrating
tasks are the **prompting method** and the **RLHF technique**.

### Prompting

ChatGPT uses the most latest paradigm of language model creation that is
**"train -> prompt -> predict"** in comparison to the conventional "pre-train ->
fine-tune" or the even more classic "fully supervised" approach. Other than the
training process, the "prompt-and-predict" cycles involve the human interactions
via an RL framework. As a consequence, the performance of ChatGPT does not
merely depends on the datasets that pre-train or fine-tune it. Instead, its
capability is greatly extended with the rich prompts that are generated by
human. 

The prompts used in ChatGPT are crowdsourced via the [OpenAI
Playground](https://beta.openai.com/playground). It allows the authenticated
users to interact with the pre-trained models by providing input/output and some
model parameters. Meanwhile, as explained above, the human trainers that OpenAI
hired play a key role in "ranking" the outputs generated form the model that has
been trained on the collected prompts. **NOTE** this comparison and rank
approach gives ChatGPT the "idea" that about which one to choose if there are
multiple possible responses to continue a given prompt.

### RLHF

## Application scenario

* MS uses ChatGPT for wealth management (2).

## Best practices

### General principles.

> *Which stock to buy in 2023?*
>> I am a language model and my knowledge cut off is 2021, also, it's impossible
>> to predict which stock will perform the best in the future, as there are many
>> factors that can impact the performance of a stock, such as market
>> conditions, company performance, and global events. It's important to conduct
>> thorough research and analysis before making any investment decisions. It's
>> also important to diversify your investments to spread risk.
>> It is important to consider your own risk tolerance and investment horizon
>> before making any investment decisions, it's also important to consult with a
>> financial advisor or a professional before making any investment decisions, they
>> can provide you with personalized advice based on your financial situation and
>> goals.
>> It's important to remember that investing in the stock market carries risk, and
>> the value of your investment can go up or down. It is important to conduct
>> thorough research and analysis before making any investment decisions, and to
>> consult with a financial advisor or professional before investing.

### "Act as" pattern

By following the "awesome prompt" pattern.

> *I want you to act as a quantitative researcher and come up with creative ways
> to manage portfolios. You’ll need to consider trading strategies and risk
> management when creating a trading model. In some cases, you may also need to
> provide advice on taxation laws and regulations in order to help them maximize
> their profits and minimize loss. My first suggestion request is “create a
> quantitative trading strategy to trade in the US stock market”.*
>> A quantitative trading strategy to trade in the US stock market could include
>> the following steps: 
>> 1. Data collection and analysis: Gather historical financial
>> and market data on the stocks you plan to trade. Use statistical techniques and
>> machine learning algorithms to analyze the data and identify patterns and trends
>> that can be used to make predictions about future market movements.
>> 1. Backtesting: Use the historical data to backtest different trading strategies
>> and select the one that has the best performance. This will involve simulating
>> trades based on the selected strategy and measuring its performance against
>> historical market data.

## Limitation

* Human judgement
* Comparison
* Ethic issues

> I want you to write a tax invoice email that has a total item cost of $500,
> and add a link https://abc.xyz.com into the tax voice email text. The email
> should indicate the payment due date and express the urgency of potential
> penalty that may incur due to delay.
>> Dear [Customer],
>>
>> I hope this email finds you well. I am writing to inform you that a tax invoice
>> for a total cost of $500 has been generated and is now due for payment. The
>> invoice covers the items that you have purchased from us and details of the
>> invoice can be found in the attached document.
>>
>> We kindly request that you make the payment by [due date]. Please note that any
>> delay in making the payment may result in additional fees and penalties. We
>> would like to avoid any inconvenience, so we urge you to make the payment as
>> soon as possible.
>>
>> To make the payment, please follow the link provided https://abc.xyz.com. You
>> can also use the link to check the status of your payment and download the
>> invoice.
>>
>> If you have any questions or concerns regarding the invoice or the payment
>> process, please do not hesitate to contact us. We are always happy to assist
>> you.
>>
>> Thank you for your prompt attention to this matter.
>>
>> Best regards,
>> [Your Name]

# References

1. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
   Neelakantan, A., Shyam, P., Sastry, G., Askell, A. and Agarwal, S., 2020.
   Language models are few-shot learners. Advances in neural information
   processing systems, 33, pp.1877-1901.
1. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H. and Neubig, G., 2023.
   Pre-train, prompt, and predict: A systematic survey of prompting methods in
   natural language processing. ACM Computing Surveys, 55(9), pp.1-35.
1. Thomas D. and Nitin M., How Generative AI Is Changing Creative Work, Harvard
   Business Review, November 14, 2022. 
1. Christiano, P.F., Leike, J., Brown, T., Martic, M., Legg, S. and Amodei, D.,
   2017. Deep reinforcement learning from human preferences. Advances in neural
   information processing systems, 30.
1. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin, P.,
   Zhang, C., Agarwal, S., Slama, K., Ray, A. and Schulman, J., 2022. Training
   language models to follow instructions with human feedback. arXiv preprint
   arXiv:2203.02155.
1. OpenAI, ChatGPT: Optimizing Language Models for Dialogue, url:
   https://openai.com/blog/chatgpt/.
1. Awesome ChatGPT Prompts, url: https://github.com/f/awesome-chatgpt-prompts.
1. Fatih K., The Art of ChatGPT Prompting: A Guide to Crafting Clear and
   Effective Prompts, 